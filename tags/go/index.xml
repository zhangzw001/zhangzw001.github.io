<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>go on zhangzw</title>
    <link>https://blog.k1s.club/tags/go/</link>
    <description>Recent content in go on zhangzw</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-hans</language>
    <copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
    <lastBuildDate>Wed, 12 Aug 2020 16:44:10 +0000</lastBuildDate><atom:link href="https://blog.k1s.club/tags/go/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>go单元测试和性能测试</title>
      <link>https://blog.k1s.club/posts/54-go%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E5%92%8C%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/</link>
      <pubDate>Wed, 12 Aug 2020 16:44:10 +0000</pubDate>
      
      <guid>https://blog.k1s.club/posts/54-go%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E5%92%8C%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/</guid>
      <description>&lt;p&gt;简单记录一下单元测试 和性能测试的例子&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>新书《Go语言编程之旅：一起用Go做项目》出版啦！</title>
      <link>https://blog.k1s.club/posts.bak/go-programming-tour-book/</link>
      <pubDate>Fri, 03 Jul 2020 21:06:33 +0800</pubDate>
      
      <guid>https://blog.k1s.club/posts.bak/go-programming-tour-book/</guid>
      <description>从我开始写技术文章起，不知不觉近三年过去了，咨询和催我出书和读者逐年递增，在 2019 年算是达到一个高峰。当然，综合考虑下我也是一直拒绝的，觉得火候还不够。
直至 2019.09 月，polaris 主动找到了我，说有事情想找我商量，本着 “如果你在纠结一件事情做还是不做，不如先做了看看结果，至少不会后悔” 的想法，更何况是长期被 Ping，因此我一口答应下来，故事自此开始了。
本书定位 本书不直接介绍 Go 语言的语法基础，内容将面向项目实践，同时会针对核心细节进行分析。而在实际项目迭代中，常常会出现或多或少的事故，因此本书也针对 Go 语言的大杀器（分析工具）以及常见问题进行了全面讲解。
本书适合已经大致学习了 Go 语言的基础语法后，想要跨越到下一个阶段的开发人员，可以填补该阶段的空白和进一步拓展你的思维方向。
读者定位  基本了解 Go 语言的语法和使用方式的开发人员。 想要进行 Go 相关项目实践和进一步摸索的开发人员。 希望熟悉 Go 常用分析工具的开发人员。  本书大纲 本书针对常见的项目类型，主要细分为 5 + 1 板块，分别是命令行、HTTP、RPC、Websocket 应用、进程内缓存以及 Go 中的大杀器。
同时我们在项目开发、细节分析、运行时分析等方方面面都进行了较深入的介绍和说明，能够为 Go 语言开发者提供相对完整的项目实践经验，而如果深入阅读第六章的章节，更能够为未来各类问题出现时的问题排查提供一份强大的知识板块。
如下为本书的思维导图概览：
如何阅读这本书 常规的列目录未免太无趣。我想不如说说从我个人的角度，所看到读者们在近 3 年来是如何阅读/实践我的实践系列文章的，其面向的读者群体是完全一致的。希望能够从另外一个角度告诉你，应当如何阅读这本书，尽可能的效益最大化。
首先，图书，买来要读，而与实战结合的图书，势必需要实践，实践最常见又分为脑内思考和上机实践：
而在持续的交流中，可以发现至少会延伸出以下几类深入层次的不同：
  第一层：只阅读，留有印象，需要时再唤醒，也行。
  第二层：阅读并实践，实打实的完成项目实践，收获丰满。
  第三层：实践的过程中，一定会遇到或大或小的问题，有的人会放弃，这就是分叉点。但有的读者会持续排查，其提升了个人能力（排错能力很重要）。
  第四层：实践完毕后，有自己的想法，认为某某地方还可以这样，也可以再实现更多的功能，举一反三，进一步拓展，并对项目提 issues 或进行 pr。
  第五层：完成整体项目后，抽离业务代码，标准化框架，实现框架的应用脚手架，并有的读者会进一步开源。
  第六层：形成脚手架后，在自己业务组开始落地，实际在项目中使用，由业务学习转化为企业实践。</description>
    </item>
    
    <item>
      <title>为什么容器内存占用居高不下，频频 OOM（续）</title>
      <link>https://blog.k1s.club/posts.bak/why-container-memory-exceed2/</link>
      <pubDate>Fri, 19 Jun 2020 21:29:08 +0800</pubDate>
      
      <guid>https://blog.k1s.club/posts.bak/why-container-memory-exceed2/</guid>
      <description>在上周的文章《为什么容器内存占用居高不下，频频 OOM》 中，我根据现状进行了分析和说明，收到了很多读者的建议和疑惑，因此有了这一篇文章，包含更进一步的说明和排查。
疑问 一般系统内存过高的情况下，可以通过 free -m 查看当前系统的内存使用情况：
在发现是系统内存占用高后，就会有读者会提到，为什么不 “手动清理 Cache”，因为 Cache 高的话，可以通过 drop_caches 的方式来清理：
 清理 page cache：  $ echo 1 &amp;gt; /proc/sys/vm/drop_caches 清理 dentries 和 inodes：  $ echo 2 &amp;gt; /proc/sys/vm/drop_caches 清理 page cache、dentries 和 inodes：  $ echo 3 &amp;gt; /proc/sys/vm/drop_caches 但新问题又出现了，因为我们的命题是在容器中，在 Kubernetes 中，若执行 drop_caches 相关命令，将会对 Node 节点上的所有其他应用程序产生影响，尤其是那些占用大量 IO 并由于缓冲区高速缓存而获得更好性能的应用程序，可能会产生 “负面” 后果。
我想这并不是一个好办法。
表象 回归原始，那就是为什么要排查这个问题，本质原因就是容器设置了 Memory Limits，而容器在运行中达到了 Limits 上限，被 OOM 掉了，所以我们想知道为什么会出现这个情况。
在前文中我们针对了五大类情况进行了猜想：
 频繁申请重复对象。 不知名内存泄露。 madvise 策略变更。 监控/判别条件有问题。 容器环境的机制。  在逐一排除后，后续发现容器的 Memory OOM 判定标准是 container_memory_working_set_bytes 指标，其实际组成为 RSS + Cache（最近访问的内存、脏内存和内核内存）。</description>
    </item>
    
    <item>
      <title>为什么容器内存占用居高不下，频频 OOM</title>
      <link>https://blog.k1s.club/posts.bak/why-container-memory-exceed/</link>
      <pubDate>Sun, 07 Jun 2020 14:52:19 +0800</pubDate>
      
      <guid>https://blog.k1s.club/posts.bak/why-container-memory-exceed/</guid>
      <description>最近我在回顾思考（写 PPT），整理了现状，发现了这个问题存在多时，经过一番波折，最终确定了元凶和相对可行的解决方案，因此也在这里分享一下排查历程。
时间线：
  在上 Kubernetes 的前半年，只是用 Kubernetes，开发没有权限，业务服务极少，忙着写新业务，风平浪静。
  在上 Kubernetes 的后半年，业务服务较少，偶尔会阶段性被运维唤醒，问之 “为什么你们的服务内存占用这么高，赶紧查”。此时大家还在为新业务冲刺，猜测也许是业务代码问题，但没有调整代码去尝试解决。
  在上 Kubernetes 的第二年，业务服务逐渐增多，普遍增加了容器限额 Limits，出现了好几个业务服务是内存小怪兽，因此如果不限制的话，服务过度占用会导致驱逐，因此反馈语也就变成了：“为什么你们的服务内存占用这么高，老被 OOM Kill，赶紧查”。据闻也有几个业务大佬有去排查（因为 OOM 反馈），似乎没得出最终解决方案。
  不禁让我们思考，为什么个别 Go 业务服务，Memory 总是提示这么高，经常达到容器限额，以至于被动 OOM Kill，是不是有什么安全隐患？
现象 内存居高不下 发现个别业务服务内存占用挺高，触发告警，且通过 Grafana 发现在凌晨（没有什么流量）的情况下，内存占用量依然拉平，没有打算下降的样子，高峰更是不得了，像是个内存炸弹：
并且我所观测的这个服务，早年还只是 100MB。现在随着业务迭代和上升，目前已经稳步 4GB，容器限额 Limits 纷纷给它开道，但我想总不能是无休止的增加资源吧，这是一个大问题。
进入重启怪圈 有的业务服务，业务量小，自然也就没有调整容器限额，因此得不到内存资源，又超过额度，就会进入疯狂的重启怪圈：
重启将近 300 次，非常不正常了，更不用提所接受到的告警通知。
排查 猜想一：频繁申请重复对象 出现问题的个别业务服务都有几个特点，那就是基本为图片处理类的功能，例如：图片解压缩、批量生成二维码、PDF 生成等，因此就怀疑是否在量大时频繁申请重复对象，而 Go 本身又没有及时释放内存，因此导致持续占用。
sync.Pool 基本上想解决 “频繁申请重复对象”，我们大多会采用多级内存池的方式，也可以用最常见的 sync.Pool，这里可参考全成所借述的《Go 夜读》上关于 sync.Pool 的分享，关于这类情况的场景：
 当多个 goroutine 都需要创建同⼀个对象的时候，如果 goroutine 数过多，导致对象的创建数⽬剧增，进⽽导致 GC 压⼒增大。形成 “并发⼤－占⽤内存⼤－GC 缓慢－处理并发能⼒降低－并发更⼤”这样的恶性循环。</description>
    </item>
    
    <item>
      <title>go简单记录</title>
      <link>https://blog.k1s.club/posts/49-go%E7%AE%80%E5%8D%95%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Wed, 27 May 2020 17:25:31 +0000</pubDate>
      
      <guid>https://blog.k1s.club/posts/49-go%E7%AE%80%E5%8D%95%E8%AE%B0%E5%BD%95/</guid>
      <description>&lt;p&gt;go的一些简单记录&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Go Modules 终极入门</title>
      <link>https://blog.k1s.club/posts.bak/go/go-moduels/2020-02-28-go-modules/</link>
      <pubDate>Fri, 28 Feb 2020 12:00:00 +0000</pubDate>
      
      <guid>https://blog.k1s.club/posts.bak/go/go-moduels/2020-02-28-go-modules/</guid>
      <description>Go modules 是 Go 语言中正式官宣的项目依赖解决方案，Go modules（前身为vgo）于 Go1.11 正式发布，在 Go1.14 已经准备好，并且可以用在生产上（ready for production）了，Go官方也鼓励所有用户从其他依赖项管理工具迁移到 Go modules。
而 Go1.14，在近期也终于正式发布，Go 官方亲自 “喊” 你来用：
因此在今天这篇文章中，我将给大家带来 Go modules 的 “终极入门”，欢迎大家一起共同探讨。
Go modules 是 Go 语言中正式官宣的项目依赖管理工具，Go modules（前身为vgo）于 Go1.11 正式发布，在 Go1.14 已经准备好，并且可以用在生产上（ready for production）了，鼓励所有用户从其他依赖项管理工具迁移到 Go modules。
什么是Go Modules Go modules 是 Go 语言的依赖解决方案，发布于 Go1.11，成长于 Go1.12，丰富于 Go1.13，正式于 Go1.14 推荐在生产上使用。
Go moudles 目前集成在 Go 的工具链中，只要安装了 Go，自然而然也就可以使用 Go moudles 了，而 Go modules 的出现也解决了在 Go1.11 前的几个常见争议问题：
 Go 语言长久以来的依赖管理问题。 “淘汰”现有的 GOPATH 的使用模式。 统一社区中的其它的依赖管理工具（提供迁移功能）。  GOPATH的那些点点滴滴 我们有提到 Go modules 的解决的问题之一就是“淘汰”掉 GOPATH，但是 GOPATH 又是什么呢，为什么在 Go1.</description>
    </item>
    
    <item>
      <title>干货满满的 Go Modules 和 goproxy.cn</title>
      <link>https://blog.k1s.club/posts.bak/go/go-moduels/2019-09-29-goproxy-cn/</link>
      <pubDate>Sun, 29 Sep 2019 12:00:00 +0000</pubDate>
      
      <guid>https://blog.k1s.club/posts.bak/go/go-moduels/2019-09-29-goproxy-cn/</guid>
      <description>大家好，我是一只普通的煎鱼，周四晚上很有幸邀请到 goproxy.cn 的作者 @盛傲飞（@aofei） 到 Go 夜读给我们进行第 61 期 《Go Modules、Go Module Proxy 和 goproxy.cn》的技术分享。
本次 @盛傲飞 的夜读分享，是对 Go Modules 的一次很好的解读，比较贴近工程实践，我必然希望把这块的知识更多的分享给大家，因此有了今天本篇文章，同时大家也可以多关注 Go 夜读，每周会通过 zoom 在线直播的方式分享 Go 相关的技术话题，希望对大家有所帮助。
前言 Go 1.11 推出的模块（Modules）为 Go 语言开发者打开了一扇新的大门，理想化的依赖管理解决方案使得 Go 语言朝着计算机编程史上的第一个依赖乌托邦（Deptopia）迈进。随着模块一起推出的还有模块代理协议（Module proxy protocol），通过这个协议我们可以实现 Go 模块代理（Go module proxy），也就是依赖镜像。
Go 1.13 的发布为模块带来了大量的改进，所以模块的扶正就是这次 Go 1.13 发布中开发者能直接感觉到的最大变化。而问题在于，Go 1.13 中的 GOPROXY 环境变量拥有了一个在中国大陆无法访问到的默认值 proxy.golang.org，经过大家在 golang/go#31755 中激烈的讨论（有些人甚至将话提上升到了“自由世界”的层次），最终 Go 核心团队仍然无法为中国开发者提供一个可在中国大陆访问的官方模块代理。
为了今后中国的 Go 语言开发者能更好地进行开发，七牛云推出了非营利性项目 goproxy.cn，其目标是为中国和世界上其他地方的 Gopher 们提供一个免费的、可靠的、持续在线的且经过 CDN 加速的模块代理。可以预见未来是属于模块化的，所以 Go 语言开发者能越早切入模块就能越早进入未来。
如果说 Go 1.11 和 Go 1.</description>
    </item>
    
    <item>
      <title>Go 应用内存占用太多，让排查？（VSZ篇）</title>
      <link>https://blog.k1s.club/posts.bak/go/talk/2019-09-24-why-vsz-large/</link>
      <pubDate>Tue, 24 Sep 2019 12:00:00 +0000</pubDate>
      
      <guid>https://blog.k1s.club/posts.bak/go/talk/2019-09-24-why-vsz-large/</guid>
      <description>前段时间，某同学说某服务的容器因为超出内存限制，不断地重启，问我们是不是有内存泄露，赶紧排查，然后解决掉，省的出问题。我们大为震惊，赶紧查看监控+报警系统和性能分析，发现应用指标压根就不高，不像有泄露的样子。
那么问题是出在哪里了呢，我们进入某个容器里查看了 top 的系统指标，结果如下：
PID VSZ RSS ... COMMAND 67459 2007m 136m ... ./eddycjy-server 从结果上来看，也没什么大开销的东西，主要就一个 Go 进程，一看，某同学就说 VSZ 那么高，而某云上的容器内存指标居然恰好和 VSZ 的值相接近，因此某同学就怀疑是不是 VSZ 所导致的，觉得存在一定的关联关系。
而从最终的结论上来讲，上述的表述是不全对的，那么在今天，本篇文章将主要围绕 Go 进程的 VSZ 来进行剖析，看看到底它为什么那么 &amp;ldquo;高&amp;rdquo;，而在正式开始分析前，第一节为前置的补充知识，大家可按顺序阅读。
基础知识 什么是 VSZ VSZ 是该进程所能使用的虚拟内存总大小，它包括进程可以访问的所有内存，其中包括了被换出的内存（Swap）、已分配但未使用的内存以及来自共享库的内存。
为什么要虚拟内存 在前面我们有了解到 VSZ 其实就是该进程的虚拟内存总大小，那如果我们想了解 VSZ 的话，那我们得先了解 “为什么要虚拟内存？”。
本质上来讲，在一个系统中的进程是与其他进程共享 CPU 和主存资源的，而在现代的操作系统中，多进程的使用非常的常见，那么如果太多的进程需要太多的内存，那么在没有虚拟内存的情况下，物理内存很可能会不够用，就会导致其中有些任务无法运行，更甚至会出现一些很奇怪的现象，例如 “某一个进程不小心写了另一个进程使用的内存”，就会造成内存破坏，因此虚拟内存是非常重要的一个媒介。
虚拟内存包含了什么 而虚拟内存，又分为内核虚拟内存和进程虚拟内存，每一个进程的虚拟内存都是独立的， 呈现如上图所示。
这里也补充说明一下，在内核虚拟内存中，是包含了内核中的代码和数据结构，而内核虚拟内存中的某些区域会被映射到所有进程共享的物理页面中去，因此你会看到 ”内核虚拟内存“ 中实际上是包含了 ”物理内存“ 的，它们两者存在映射关系。而在应用场景上来讲，每个进程也会去共享内核的代码和全局数据结构，因此就会被映射到所有进程的物理页面中去。
虚拟内存的重要能力 为了更有效地管理内存并且减少出错，现代系统提供了一种对主存的抽象概念，也就是今天的主角，叫做虚拟内存（VM），虚拟内存是硬件异常、硬件地址翻译、主存、磁盘文件和内核软件交互的地方，它为每个进程提供了一个大的、一致的和私有的地址空间，虚拟内存提供了三个重要的能力：
 它将主存看成是一个存储在磁盘上的地址空间的高速缓存，在主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据，通过这种方式，它高效地使用了主存。 它为每个进程提供了一致的地址空间，从而简化了内存管理。 它保护了每个进程的地址空间不被其他进程破坏。  小结 上面发散的可能比较多，简单来讲，对于本文我们重点关注这些知识点，如下：
 虚拟内存它是有各式各样内存交互的地方，它包含的不仅仅是 &amp;ldquo;自己&amp;rdquo;，而在本文中，我们只需要关注 VSZ，也就是进程虚拟内存，它包含了你的代码、数据、堆、栈段和共享库。 虚拟内存作为内存保护的工具，能够保证进程之间的内存空间独立，不受其他进程的影响，因此每一个进程的 VSZ 大小都不一样，互不影响。 虚拟内存的存在，系统给各进程分配的内存之和是可以大于实际可用的物理内存的，因此你也会发现你进程的物理内存总是比虚拟内存低的多的多。  排查问题 在了解了基础知识后，我们正式开始排查问题，第一步我们先编写一个测试程序，看看没有什么业务逻辑的 Go 程序，它初始的 VSZ 是怎么样的。</description>
    </item>
    
    <item>
      <title>Go1.13 defer 的性能是如何提高的</title>
      <link>https://blog.k1s.club/posts.bak/go/talk/2019-09-07-go1.13-defer/</link>
      <pubDate>Sat, 07 Sep 2019 12:00:00 +0000</pubDate>
      
      <guid>https://blog.k1s.club/posts.bak/go/talk/2019-09-07-go1.13-defer/</guid>
      <description>最近 Go1.13 终于发布了，其中一个值得关注的特性就是 defer 在大部分的场景下性能提升了30%，但是官方并没有具体写是怎么提升的，这让大家非常的疑惑。而我因为之前写过《深入理解 Go defer》 和 《Go defer 会有性能损耗，尽量不要用？》 这类文章，因此我挺感兴趣它是做了什么改变才能得到这样子的结果，所以今天和大家一起探索其中奥妙。
一、测试 Go1.12 $ go test -bench=. -benchmem -run=none goos: darwin goarch: amd64 pkg: github.com/EDDYCJY/awesomeDefer BenchmarkDoDefer-4 20000000	91.4 ns/op	48 B/op	1 allocs/op BenchmarkDoNotDefer-4 30000000	41.6 ns/op	48 B/op	1 allocs/op PASS ok github.com/EDDYCJY/awesomeDefer	3.234s Go1.13 $ go test -bench=. -benchmem -run=none goos: darwin goarch: amd64 pkg: github.com/EDDYCJY/awesomeDefer BenchmarkDoDefer-4 15986062	74.7 ns/op	48 B/op	1 allocs/op BenchmarkDoNotDefer-4 29231842	40.3 ns/op	48 B/op	1 allocs/op PASS ok github.</description>
    </item>
    
    <item>
      <title>用 GODEBUG 看 GC</title>
      <link>https://blog.k1s.club/posts.bak/go/tools/2019-09-02-godebug-gc/</link>
      <pubDate>Mon, 02 Sep 2019 12:00:00 +0000</pubDate>
      
      <guid>https://blog.k1s.club/posts.bak/go/tools/2019-09-02-godebug-gc/</guid>
      <description>什么是 GC 在计算机科学中，垃圾回收（GC）是一种自动管理内存的机制，垃圾回收器会去尝试回收程序不再使用的对象及其占用的内存。而最早 John McCarthy 在 1959 年左右发明了垃圾回收，以简化 Lisp 中的手动内存管理的机制（来自 wikipedia）。
为什么要 GC 手动管理内存挺麻烦，管错或者管漏内存也很糟糕，将会直接导致程序不稳定（持续泄露）甚至直接崩溃。
GC 带来的问题 硬要说会带来什么问题的话，也就数大家最关注的 Stop The World（STW），STW 代指在执行某个垃圾回收算法的某个阶段时，需要将整个应用程序暂停去处理 GC 相关的工作事项。例如：
   行为 会不会 STW 为什么     标记开始 会 在开始标记时，准备根对象的扫描，会打开写屏障（Write Barrier） 和 辅助GC（mutator assist），而回收器和应用程序是并发运行的，因此会暂停当前正在运行的所有 Goroutine。   并发标记中 不会 标记阶段，主要目的是标记堆内存中仍在使用的值。   标记结束 会 在完成标记任务后，将重新扫描部分根对象，这时候会禁用写屏障（Write Barrier）和辅助GC（mutator assist），而标记阶段和应用程序是并发运行的，所以在标记阶段可能会有新的对象产生，因此在重新扫描时需要进行 STW。    如何调整 GC 频率 可以通过 GOGC 变量设置初始垃圾收集器的目标百分比值，对比的规则为当新分配的数值与上一次收集后剩余的实时数值的比例达到设置的目标百分比时，就会触发 GC，默认值为 GOGC=100。如果将其设置为 GOGC=off 可以完全禁用垃圾回收器，要不试试？
简单来讲就是，GOGC 的值设置的越大，GC 的频率越低，但每次最终所触发到 GC 的堆内存也会更大。</description>
    </item>
    
  </channel>
</rss>
