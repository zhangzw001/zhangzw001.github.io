<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>数据分析 on zhangzw</title>
    <link>https://blog.k1s.club/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/</link>
    <description>Recent content in 数据分析 on zhangzw</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-hans</language>
    <copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
    <lastBuildDate>Sat, 28 Apr 2018 12:30:00 +0000</lastBuildDate><atom:link href="https://blog.k1s.club/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>了解一下Golang的市场行情</title>
      <link>https://blog.k1s.club/posts.bak/go/crawler/2018-04-28-go2018/</link>
      <pubDate>Sat, 28 Apr 2018 12:30:00 +0000</pubDate>
      
      <guid>https://blog.k1s.club/posts.bak/go/crawler/2018-04-28-go2018/</guid>
      <description>项目地址：https://github.com/go-crawler/lagou_jobs
如果对你有所帮助，欢迎 Star，给文章来波赞，这样可以让更多的人看见 :)
目标 在工作中 Golang 已是一份子，想让大家了解一下 Golang 的市场行情，也想让更多的人熟悉它。因此主要是展示数据分析的结果
目标站点是 某招聘网站 的职位数据抓取和分析，爬取城市分别为 北京、上海、广州、深圳、杭州、成都，再得出一个结论
分析 首先需要进行页面分析，找到我们的抓取方向
搜索 golang 关键字，打开页面 F12 就能看到它发送了四个请求，留意 positionAjax.json 这个请求
我们仔细研判这个接口的入参和出参
入参 1、Query String Param
  city：请求的城市
  needAddtionalResult：是否需要补充额外的参数，这里默认 false
  2、Form Data
 first：是否首页 pn：页码 kd：关键字  出参 就是它了，从返回结果可得出许多有用的信息
 companyFullName：公司全称 companyLabelList：公司标签 companyShortName：公司简称 companySize：公司规模 education：学历要求 financeStage：融资阶段  等等~
分页 在上面两张图中，可以发现在 content 节点中包含 pageNo、pageSize 字段，content.positionResult 节点有 totalCount 字段，可以得知当前是第几页，每页显示多少条，当前的职位总条数
需要注意一下，分页的计算是要向上取整的
模拟浏览器头 User-Agent 可以用 fake-useragent 这个项目来随机生成 UA 头 😄</description>
    </item>
    
    <item>
      <title>爬取汽车之家 二手车产品库</title>
      <link>https://blog.k1s.club/posts.bak/go/crawler/2018-04-01-cars/</link>
      <pubDate>Sun, 01 Apr 2018 12:30:00 +0000</pubDate>
      
      <guid>https://blog.k1s.club/posts.bak/go/crawler/2018-04-01-cars/</guid>
      <description>项目地址：https://github.com/go-crawler/car-prices
目标 最近经常有人在耳边提起汽车之家，也好奇二手车在国内的价格是怎么样的，因此本次的目标站点是 汽车之家 的二手车产品库
分析目标源：
 一页共 24 条 含分页，但这个老产品库，在 100 页后会存在问题，因此我们爬取 99 页 可以获取全部城市 共可爬取 19w+ 数据  开始 爬取步骤
 获取全部的城市 拼装全部城市 URL 入队列 解析二手车页面结构 下一页 URL 入队列 循环拉取所有分页的二手车数据 循环拉取队列中城市的二手车数据 等待，确定队列中无新的 URL 爬取的二手车数据入库  获取城市 通过页面查看，可发现在城市筛选区可得到全部的二手车城市列表，但是你仔细查阅代码。会发现它是 JS 加载进来的，城市也统一放在了一个变量中
有两种提取方法
 分析 JS 变量，提取出来 直接将 areaJson 复制出来作为变量解析  在这里我们直接将其复制粘贴出来即可，因为这是比较少变动的值
获取分页 通过分析页面可以得知分页链接是有一定规律的，例如：/2sc/hangzhou/a0_0msdgscncgpi1ltocsp2exb4/，可以发现 sp%d，sp 后面为页码
按照常理，可以通过预测所有分页链接，推入队列后 go routine 一波 即可快速拉取
但是在这老产品库存在一个问题，在超过 100 页后，下一页永远是 101 页
因此我们采取比较传统的做法，通过拉取下一页的链接去访问，以便适应可能的分页链接改变； 100 页以后的分页展示也很奇怪，先忽视
获取二手车数据 页面结构较为固定，常规的清洗 HTML 即可</description>
    </item>
    
    <item>
      <title>爬取豆瓣电影 Top250</title>
      <link>https://blog.k1s.club/posts.bak/go/crawler/2018-03-21-douban-top250/</link>
      <pubDate>Wed, 21 Mar 2018 12:30:00 +0000</pubDate>
      
      <guid>https://blog.k1s.club/posts.bak/go/crawler/2018-03-21-douban-top250/</guid>
      <description>爬虫是标配了，看数据那一刻很有趣。第一个就从最最最简单最基础的爬虫开始写起吧！
项目地址：https://github.com/go-crawler/douban-movie
目标 我们的目标站点是 豆瓣电影 Top250，估计大家都很眼熟了
本次爬取 8 个字段，用于简单的概括分析。具体的字段如下：
简单的分析一下目标源
 一页共 25 条 含分页（共 10 页）且分页规则是正常的 每一项的数据字段排序都是规则且不变  开始 由于量不大，我们的爬取步骤如下
 分析页面，获取所有的分页 分析页面，循环爬取所有页面的电影信息 爬取的电影信息入库  安装 $ go get -u github.com/PuerkitoBio/goquery 运行 $ go run main.go 代码片段 1、获取所有分页 func ParsePages(doc *goquery.Document) (pages []Page) { pages = append(pages, Page{Page: 1, Url: &amp;#34;&amp;#34;}) doc.Find(&amp;#34;#content &amp;gt; div &amp;gt; div.article &amp;gt; div.paginator &amp;gt; a&amp;#34;).Each(func(i int, s *goquery.Selection) { page, _ := strconv.Atoi(s.Text()) url, _ := s.</description>
    </item>
    
  </channel>
</rss>
