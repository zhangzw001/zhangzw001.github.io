<!DOCTYPE html>
<html lang="zh-hans">

<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta http-equiv="X-UA-Compatible" content="ie=edge">
	<meta name="theme-color" content="#494f5c">
	<meta name="msapplication-TileColor" content="#494f5c">
<meta itemprop="name" content="kubeadm安装高可用k8s集群">
<meta itemprop="description" content="简单记录kubeadm方式安装k8s1.16.4高可用集群,haproxy通过keepalived绑定的vip来负载均衡到三台master, 其中keepalived则反之单机故障,haproxy则让三台master可以同时提供服务.
 Centos7.6部署k8s v1.16.4高可用集群(主备模式) 使用kubeadm搭建高可用k8s v1.16.3集群(keepalived&#43;haproxy)
   一、 安装准备  1.1 主机名  192.168.53.106 master01.k8s.io 192.168.53.107 master02.k8s.io 192.168.53.108 master03.k8s.io 192.168.53.137 master.k8s.io  1.2 同步时间, 设置时区  * * * * * /usr/sbin/ntpdate time.nist.gov timedatectl set-timezone Asia/Shanghai 或者 ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime  1.3 关闭SElinux  setenforce 0 sed -i &quot;s/^SELINUX=enforcing/SELINUX=disabled/g&quot; /etc/sysconfig/selinux sed -i &quot;s/^SELINUX=enforcing/SELINUX=disabled/g&quot; /etc/selinux/config sed -i &quot;s/^SELINUX=permissive/SELINUX=disabled/g&quot; /etc/sysconfig/selinux sed -i &quot;s/^SELINUX=permissive/SELINUX=disabled/g&quot; /etc/selinux/config  1.4 关闭swap(否则kubeadm init或join会报错)  &gt; swapoff -a &amp;&amp; sysctl -w vm.">
<meta itemprop="datePublished" content="2020-03-24T11:10:41+00:00" />
<meta itemprop="dateModified" content="2020-03-24T11:10:41+00:00" />
<meta itemprop="wordCount" content="1443">



<meta itemprop="keywords" content="k8s," />
<meta property="og:title" content="kubeadm安装高可用k8s集群" />
<meta property="og:description" content="简单记录kubeadm方式安装k8s1.16.4高可用集群,haproxy通过keepalived绑定的vip来负载均衡到三台master, 其中keepalived则反之单机故障,haproxy则让三台master可以同时提供服务.
 Centos7.6部署k8s v1.16.4高可用集群(主备模式) 使用kubeadm搭建高可用k8s v1.16.3集群(keepalived&#43;haproxy)
   一、 安装准备  1.1 主机名  192.168.53.106 master01.k8s.io 192.168.53.107 master02.k8s.io 192.168.53.108 master03.k8s.io 192.168.53.137 master.k8s.io  1.2 同步时间, 设置时区  * * * * * /usr/sbin/ntpdate time.nist.gov timedatectl set-timezone Asia/Shanghai 或者 ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime  1.3 关闭SElinux  setenforce 0 sed -i &quot;s/^SELINUX=enforcing/SELINUX=disabled/g&quot; /etc/sysconfig/selinux sed -i &quot;s/^SELINUX=enforcing/SELINUX=disabled/g&quot; /etc/selinux/config sed -i &quot;s/^SELINUX=permissive/SELINUX=disabled/g&quot; /etc/sysconfig/selinux sed -i &quot;s/^SELINUX=permissive/SELINUX=disabled/g&quot; /etc/selinux/config  1.4 关闭swap(否则kubeadm init或join会报错)  &gt; swapoff -a &amp;&amp; sysctl -w vm." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.ngirl.xyz/posts/42-kubeadm%E5%AE%89%E8%A3%85%E9%AB%98%E5%8F%AF%E7%94%A8k8s%E9%9B%86%E7%BE%A4/" />
<meta property="article:published_time" content="2020-03-24T11:10:41+00:00" />
<meta property="article:modified_time" content="2020-03-24T11:10:41+00:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="kubeadm安装高可用k8s集群"/>
<meta name="twitter:description" content="简单记录kubeadm方式安装k8s1.16.4高可用集群,haproxy通过keepalived绑定的vip来负载均衡到三台master, 其中keepalived则反之单机故障,haproxy则让三台master可以同时提供服务.
 Centos7.6部署k8s v1.16.4高可用集群(主备模式) 使用kubeadm搭建高可用k8s v1.16.3集群(keepalived&#43;haproxy)
   一、 安装准备  1.1 主机名  192.168.53.106 master01.k8s.io 192.168.53.107 master02.k8s.io 192.168.53.108 master03.k8s.io 192.168.53.137 master.k8s.io  1.2 同步时间, 设置时区  * * * * * /usr/sbin/ntpdate time.nist.gov timedatectl set-timezone Asia/Shanghai 或者 ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime  1.3 关闭SElinux  setenforce 0 sed -i &quot;s/^SELINUX=enforcing/SELINUX=disabled/g&quot; /etc/sysconfig/selinux sed -i &quot;s/^SELINUX=enforcing/SELINUX=disabled/g&quot; /etc/selinux/config sed -i &quot;s/^SELINUX=permissive/SELINUX=disabled/g&quot; /etc/sysconfig/selinux sed -i &quot;s/^SELINUX=permissive/SELINUX=disabled/g&quot; /etc/selinux/config  1.4 关闭swap(否则kubeadm init或join会报错)  &gt; swapoff -a &amp;&amp; sysctl -w vm."/>

	<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
	<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
	<link rel="manifest" href="/site.webmanifest">
	<link rel="mask-icon" href="/safari-pinned-tab.svg" color="">
	<link rel="shortcut icon" href="/favicon.ico">

	<title>kubeadm安装高可用k8s集群</title>
	<link rel="stylesheet" href="https://www.ngirl.xyz/css/style.min.d3141168199607bf3a517216ce3c263814eecdbc8fca72a9a88700799a838219.css">
	
</head>

<body id="page">
	
	<header id="site-header" class="animated slideInUp faster">
		<div class="hdr-wrapper section-inner">
			<div class="hdr-left">
				<div class="site-branding">
					<a href="https://www.ngirl.xyz">zhangzw</a>
				</div>
				<nav class="site-nav hide-in-mobile">
					<a href="https://www.ngirl.xyz/golang/">golang</a>
					<a href="https://www.ngirl.xyz/posts/">文章</a>
				</nav>
			</div>
			<div class="hdr-right hdr-icons">
				<button id="toc-btn" class="hdr-btn desktop-only-ib" title="Table of Contents"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-list"><line x1="8" y1="6" x2="21" y2="6"></line><line x1="8" y1="12" x2="21" y2="12"></line><line x1="8" y1="18" x2="21" y2="18"></line><line x1="3" y1="6" x2="3" y2="6"></line><line x1="3" y1="12" x2="3" y2="12"></line><line x1="3" y1="18" x2="3" y2="18"></line></svg></button><span class="hdr-social hide-in-mobile"><a href="https://github.com/zhangzw001" target="_blank" rel="noopener me" title="Github"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg></a></span><button id="menu-btn" class="hdr-btn" title="Menu"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></button>
			</div>
		</div>
	</header>
	<div id="mobile-menu" class="animated fast">
		<ul>
			<li><a href="https://www.ngirl.xyz/posts/">文章</a></li>
			<li><a href="https://www.ngirl.xyz/tags/">标签</a></li>
			<li><a href="https://www.ngirl.xyz/about/">关于</a></li>
		</ul>
	</div>



	<main class="site-main section-inner animated fadeIn faster">
		<article class="thin">
			<header class="post-header">
				<div class="post-meta"><span>Mar 24, 2020</span></div>
				<h1>kubeadm安装高可用k8s集群</h1>
			</header>
			<div class="content">
				<p>简单记录kubeadm方式安装k8s1.16.4高可用集群,haproxy通过keepalived绑定的vip来负载均衡到三台master, 其中keepalived则反之单机故障,haproxy则让三台master可以同时提供服务.</p>
<p><img src="//zhangzw001.github.io/images/42/01.png" alt=""></p>
<!--more -->
<blockquote>
<p><a href="https://www.kubernetes.org.cn/6632.html">Centos7.6部署k8s v1.16.4高可用集群(主备模式)</a>
<a href="https://www.cnblogs.com/ssgeek/p/11942062.html">使用kubeadm搭建高可用k8s v1.16.3集群(keepalived+haproxy)</a></p>
</blockquote>
<center>
<img src="//zhangzw001.github.io/images/dockerniu.jpeg" width = "100" height = "100" style="border: 0"/>
</center>
<h3 id="一-安装准备">一、 安装准备<a href="#一-安装准备" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>
<ul>
<li>1.1 主机名</li>
</ul>
<pre><code>192.168.53.106 master01.k8s.io
192.168.53.107 master02.k8s.io
192.168.53.108 master03.k8s.io
192.168.53.137 master.k8s.io
</code></pre><ul>
<li>1.2 同步时间, 设置时区</li>
</ul>
<pre><code>* * * * * /usr/sbin/ntpdate time.nist.gov

timedatectl set-timezone Asia/Shanghai
或者
ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
</code></pre><ul>
<li>1.3 关闭SElinux</li>
</ul>
<pre><code>setenforce  0
sed -i &quot;s/^SELINUX=enforcing/SELINUX=disabled/g&quot; /etc/sysconfig/selinux
sed -i &quot;s/^SELINUX=enforcing/SELINUX=disabled/g&quot; /etc/selinux/config
sed -i &quot;s/^SELINUX=permissive/SELINUX=disabled/g&quot; /etc/sysconfig/selinux
sed -i &quot;s/^SELINUX=permissive/SELINUX=disabled/g&quot; /etc/selinux/config  
</code></pre><ul>
<li>1.4 关闭swap(否则kubeadm init或join会报错)</li>
</ul>
<pre><code>&gt; swapoff -a &amp;&amp; sysctl -w vm.swappiness=0
vm.swappiness = 0
或 swapoff -a

#/etc/fstab也要注解掉SWAP挂载。
sed -i.$(date +%F).bak '/swap/s/^/#/' /etc/fstab
#sed -i 's/.*swap.*/#&amp;/' /etc/fstab

</code></pre><ul>
<li>1.5 配置系统内核参数</li>
</ul>
<pre><code>使流过网桥的流量也进入iptables/netfilter框架中，在/etc/sysctl.conf中添加以下配置
cat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables = 1
net.bridge.bridge-nf-call-ip6tables = 1
EOF

sysctl -p /etc/sysctl.d/k8s.conf
</code></pre><blockquote>
<p>如果出现报错</p>
</blockquote>
<pre><code>sysctl: cannot stat /proc/sys/net/bridge/bridge-nf-call-iptables: No such file or directory
sysctl: cannot stat /proc/sys/net/bridge/bridge-nf-call-ip6tables: No such file or directory
</code></pre><blockquote>
<p>报错解决:</p>
</blockquote>
<pre><code># 执行以下命令
1 modprobe br_netfilter
2 ls /proc/sys/net/bridge
3 sysctl -p /etc/sysctl.d/k8s.conf
</code></pre><ul>
<li>1.6 设置k8s源</li>
</ul>
<pre><code>cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF

yum clean all
yum makecache -y
</code></pre><pre><code>[] 中括号中的是repository id，唯一，用来标识不同仓库
name 仓库名称，自定义
baseurl 仓库地址
enable 是否启用该仓库，默认为1表示启用
gpgcheck 是否验证从该仓库获得程序包的合法性，1为验证
repo_gpgcheck 是否验证元数据的合法性 元数据就是程序包列表，1为验证
gpgkey=URL 数字签名的公钥文件所在位置，如果gpgcheck值为1，此处就需要指定gpgkey文件的位置，如果gpgcheck值为0就不需要此项了
</code></pre><ul>
<li>
<p>1.7 免密登录配置</p>
<p>略</p>
</li>
</ul>
<center>
<img src="//zhangzw001.github.io/images/dockerniu.jpeg" width = "100" height = "100" style="border: 0"/>
</center>
<h3 id="二-docker版本安装">二、 docker版本安装<a href="#二-docker版本安装" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>
<ul>
<li>2.1 配置源</li>
</ul>
<pre><code>yum install -y yum-utils device-mapper-persistent-data lvm2 bash-completion
yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
yum install docker-ce-18.09.9 docker-ce-cli-18.09.9 containerd.io -y

# 高版本降级
yum downgrade --setopt=obsoletes=0 -y docker-ce-18.09.9 docker-ce-cli-18.09.9
</code></pre><ul>
<li>2.2 配置阿里云镜像加速器</li>
</ul>
<blockquote>
<p>登陆地址为：https://cr.console.aliyun.com ,未注册的可以先注册阿里云账户</p>
</blockquote>
<pre><code>mkdir -p /etc/docker
tee /etc/docker/daemon.json &lt;&lt;-'EOF'
{
&quot;registry-mirrors&quot;: [&quot;https://0aqwccdy.mirror.aliyuncs.com&quot;]
}
EOF
</code></pre><ul>
<li>2.3 启动docker</li>
</ul>
<pre><code>systemctl restart docker
systemctl enable docker
</code></pre><ul>
<li>2.4 修改Cgroup Driver</li>
</ul>
<blockquote>
<p>修改daemon.json，新增‘”exec-opts”: [“native.cgroupdriver=systemd”’</p>
</blockquote>
<pre><code>cat /etc/docker/daemon.json
{
  &quot;registry-mirrors&quot;: [&quot;https://0aqwccdy.mirror.aliyuncs.com&quot;],
  &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;]
}
</code></pre><blockquote>
<p>重新加载docker</p>
</blockquote>
<pre><code>systemctl restart docker
systemctl enable docker
</code></pre><blockquote>
<p>修改cgroupdriver是为了消除告警：</p>
</blockquote>
<pre><code>[WARNING IsDockerSystemdCheck]: detected “cgroupfs” as the Docker cgroup driver. The recommended driver is “systemd”. Please follow the guide at https://kubernetes.io/docs/setup/cri/
</code></pre><center>
<img src="//zhangzw001.github.io/images/dockerniu.jpeg" width = "100" height = "100" style="border: 0"/>
</center>
<h3 id="三-keepalived安装">三、 keepalived安装<a href="#三-keepalived安装" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>
<ul>
<li>3.1 安装</li>
</ul>
<pre><code>yum -y install keepalived
</code></pre><ul>
<li>3.2 master01.k8s.io上配置</li>
</ul>
<pre><code>tee /etc/keepalived/keepalived.conf &lt;&lt;- 'EOF'
! Configuration File for keepalived
global_defs {
   router_id master01.k8s.io
}

vrrp_script check_haproxy {
    script &quot;killall -0 haproxy&quot;
    interval 3
    weight -2
    fall 10
    rise 2
}

vrrp_instance VI_1 {
    state MASTER
    interface enp0s3
    virtual_router_id 51
    priority 250
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    virtual_ipaddress {
        192.168.53.137
    }
    track_script {
        check_haproxy
    }
}
EOF
</code></pre><ul>
<li>3.3 master02.k8s.io,master03.k8s.io上配置</li>
</ul>
<pre><code>tee /etc/keepalived/keepalived.conf &lt;&lt;- 'EOF'
! Configuration File for keepalived
global_defs {
   router_id master02.k8s.io
}

vrrp_script check_haproxy {
    script &quot;killall -0 haproxy&quot;
    interval 3
    weight -2
    fall 10
    rise 2
}

vrrp_instance VI_1 {
    state BACKUP
    interface enp0s3
    virtual_router_id 51
    priority 200
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    virtual_ipaddress {
       192.168.53.137
    }
    track_script {
        check_haproxy
    }
}
EOF


tee /etc/keepalived/keepalived.conf &lt;&lt;- 'EOF'
! Configuration File for keepalived
global_defs {
   router_id master03.k8s.io
}

vrrp_script check_haproxy {
    script &quot;killall -0 haproxy&quot;
    interval 3
    weight -2
    fall 10
    rise 2
}

vrrp_instance VI_1 {
    state BACKUP
    interface enp0s3
    virtual_router_id 51
    priority 150
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    virtual_ipaddress {
        192.168.53.137
    }
    track_script {
        check_haproxy
    }
}
EOF
</code></pre><ul>
<li>3.4 master02.k8s.io,master03.k8s.io上启动keepalived</li>
</ul>
<pre><code>service keepalived start
systemctl enable keepalived
</code></pre><ul>
<li>3.5 测试</li>
</ul>
<pre><code># 首先 ip a查看ip否则绑定成功

# ping 192.168.53.137 是否正常

# 在master01.k8s.io上 停止服务 service keepalived stop

# 在master02.k8s.io或master03.k8s.io上查看ip a是否存在192.168.53.137, 检查ping 192.168.53.137 是否正常
</code></pre><center>
<img src="//zhangzw001.github.io/images/dockerniu.jpeg" width = "100" height = "100" style="border: 0"/>
</center>
<h3 id="四-haproxy安装">四、 haproxy安装<a href="#四-haproxy安装" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>
<ul>
<li>
<p>4.1 安装</p>
<pre><code></code></pre></li>
</ul>
<p>yum install -y haproxy</p>
<pre><code>
- 4.2 配置
&gt; 三台master节点的配置均相同，配置中声明了后端代理的三个master节点服务器，指定了haproxy运行的端口为16443等，因此16443端口为集群的入口，其他的配置不做赘述。
</code></pre><p>tee  /etc/haproxy/haproxy.cfg &laquo;- &lsquo;EOF&rsquo;
#&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;</p>
<h1 id="global-settings">Global settings<a href="#global-settings" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h1>
<p>#&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;
global
# to have these messages end up in /var/log/haproxy.log you will
# need to:
# 1) configure syslog to accept network log events.  This is done
#    by adding the &lsquo;-r&rsquo; option to the SYSLOGD_OPTIONS in
#    /etc/sysconfig/syslog
# 2) configure local2 events to go to the /var/log/haproxy.log
#   file. A line like the following can be added to
#   /etc/sysconfig/syslog
#
#    local2.*                       /var/log/haproxy.log
#
log         127.0.0.1 local2</p>
<pre><code>chroot      /var/lib/haproxy
pidfile     /var/run/haproxy.pid
maxconn     4000
user        haproxy
group       haproxy
daemon

# turn on stats unix socket
stats socket /var/lib/haproxy/stats
</code></pre>
<p>#&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;</p>
<h1 id="common-defaults-that-all-the-listen-and-backend-sections-will">common defaults that all the &lsquo;listen&rsquo; and &lsquo;backend&rsquo; sections will<a href="#common-defaults-that-all-the-listen-and-backend-sections-will" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h1>
<h1 id="use-if-not-designated-in-their-block">use if not designated in their block<a href="#use-if-not-designated-in-their-block" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h1>
<p>#&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;<br>
defaults
mode                    http
log                     global
option                  httplog
option                  dontlognull
option http-server-close
option forwardfor       except 127.0.0.0/8
option                  redispatch
retries                 3
timeout http-request    10s
timeout queue           1m
timeout connect         10s
timeout client          1m
timeout server          1m
timeout http-keep-alive 10s
timeout check           10s
maxconn                 3000
#&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;</p>
<h1 id="kubernetes-apiserver-frontend-which-proxys-to-the-backends">kubernetes apiserver frontend which proxys to the backends<a href="#kubernetes-apiserver-frontend-which-proxys-to-the-backends" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h1>
<p>#&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;
frontend kubernetes-apiserver
mode                 tcp
bind                 *:16443
option               tcplog
default_backend      kubernetes-apiserver <br>
#&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;</p>
<h1 id="round-robin-balancing-between-the-various-backends">round robin balancing between the various backends<a href="#round-robin-balancing-between-the-various-backends" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h1>
<p>#&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;
backend kubernetes-apiserver
mode        tcp
balance     roundrobin
server      master01.k8s.io   192.168.53.106:6443 check
server      master02.k8s.io   192.168.53.107:6443 check
server      master03.k8s.io   192.168.53.108:6443 check
#&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;</p>
<h1 id="collection-haproxy-statistics-message">collection haproxy statistics message<a href="#collection-haproxy-statistics-message" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h1>
<p>#&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;
listen stats
bind                 *:1080
stats auth           admin:awesomePassword
stats refresh        5s
stats realm          HAProxy\ Statistics
stats uri            /admin?stats
EOF</p>
<pre><code>
- 4.3 启动

</code></pre><p>systemctl enable haproxy
systemctl start haproxy
systemctl status haproxy
netstat -lnptu|grep haproxy</p>
<pre><code>
&lt;center&gt;
&lt;img src=&quot;//zhangzw001.github.io/images/dockerniu.jpeg&quot; width = &quot;100&quot; height = &quot;100&quot; style=&quot;border: 0&quot;/&gt;
&lt;/center&gt;

### 五、 k8s安装

- 5.1 版本查看

</code></pre><p>yum list kubelet &ndash;showduplicates | sort -r</p>
<pre><code>
&gt; 本文安装的kubelet版本是1.16.4，该版本支持的docker版本为1.13.1, 17.03, 17.06, 17.09, 18.06, 18.09。

- 5.2 安装kubelet、kubeadm和kubectl

</code></pre><p>yum install -y kubelet-1.16.4 kubeadm-1.16.4 kubectl-1.16.4</p>
<pre><code>
&gt; kubelet 运行在集群所有节点上，用于启动Pod和容器等对象的工具
&gt; kubeadm 用于初始化集群，启动集群的命令工具
&gt; kubectl 用于和集群通信的命令行，通过kubectl可以部署和管理应用，查看各种资源，创建、删除和更新各种组件

- 5.3 启动kubelet

</code></pre><p>systemctl enable kubelet
systemctl start kubelet</p>
<pre><code>
- 5.4 kubectl命令补全

</code></pre><h1 id="bash">bash<a href="#bash" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h1>
<p>echo &ldquo;source &lt;(kubectl completion bash)&rdquo; &raquo; ~/.bash_profile
source ~/.bash_profile</p>
<h1 id="zsh">zsh<a href="#zsh" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h1>
<p>echo &ldquo;source &lt;(kubectl completion zsh)&rdquo; &raquo; ~/.zshrc
source ~/.zshrc</p>
<pre><code>
- 5.5 下载镜像
&gt; 外网的慢, 从阿里云下载后打个官方tag即可

</code></pre><p>tee /root/image.sh &laquo;- &lsquo;EOF&rsquo;
#!/bin/bash
#url=registry.cn-hangzhou.aliyuncs.com/loong576
url=registry.aliyuncs.com/google_containers
version=v1.16.4
images=(<code>kubeadm config images list --kubernetes-version=$version|awk -F '/' '{print $2}'</code>)
for imagename in ${images[@]} ; do
docker pull $url/$imagename
docker tag $url/$imagename k8s.gcr.io/$imagename
docker rmi -f $url/$imagename
done
EOF</p>
<h1 id="下载">下载<a href="#下载" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h1>
<p>sh  /root/image.sh</p>
<h1 id="验证">验证<a href="#验证" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h1>
<p>docker images|grep 1.16.4
k8s.gcr.io/kube-apiserver                  v1.16.4              3722a80984a0        3 months ago        217MB
k8s.gcr.io/kube-controller-manager         v1.16.4              fb4cca6b4e4c        3 months ago        163MB
k8s.gcr.io/kube-proxy                      v1.16.4              091df896d78f        3 months ago        86.1MB
k8s.gcr.io/kube-scheduler                  v1.16.4              2984964036c8        3 months ago        87.3MB
k8s.gcr.io/metrics-server-amd64            v0.3.5               abf04c0f54ff        6 months ago        39.9MB
k8s.gcr.io/etcd                            3.3.15-0             b2756210eeab        6 months ago        247MB
k8s.gcr.io/coredns                         1.6.2                bf261d157914        7 months ago        44.1MB
k8s.gcr.io/pause                           3.1                  da86e6ba6ca1        2 years ago         742kB</p>
<pre><code>
&lt;center&gt;
&lt;img src=&quot;//zhangzw001.github.io/images/dockerniu.jpeg&quot; width = &quot;100&quot; height = &quot;100&quot; style=&quot;border: 0&quot;/&gt;
&lt;/center&gt;

### 六、初始化master

- 6.1 kubeadm.1.16.4.conf

&gt; 在具有vip的master上操作，这里为master01.k8s.io

</code></pre><p>tee /data/k8s-config/kubeadm.1.16.4.conf &laquo;- &lsquo;EOF&rsquo;
apiVersion: kubeadm.k8s.io/v1beta2
kind: ClusterConfiguration
kubernetesVersion: v1.16.4
apiServer:
certSANs:    #填写所有kube-apiserver节点的hostname、IP、VIP</p>
<ul>
<li>master01.k8s.io</li>
<li>master02.k8s.io</li>
<li>master03.k8s.io</li>
<li>master.k8s.io</li>
<li>dk-node1</li>
<li>192.168.53.106</li>
<li>192.168.53.107</li>
<li>192.168.53.108</li>
<li>192.168.53.137</li>
<li>192.168.0.136</li>
<li>127.0.0.1
controlPlaneEndpoint: &ldquo;master.k8s.io:16443&rdquo;
networking:
podSubnet: &ldquo;10.244.0.0/16&rdquo;
EOF</li>
</ul>
<pre><code>
- 6.2 master初始化

</code></pre><p>kubeadm init &ndash;config=kubeadm.1.16.4.conf</p>
<pre><code>
</code></pre><p>You can now join any number of control-plane nodes by copying certificate authorities
and service account keys on each node and then running the following as root:</p>
<p>kubeadm join master.k8s.io:16443 &ndash;token ynaob5.49rz8ofxavp6hzes<br>
&ndash;discovery-token-ca-cert-hash sha256:6e7859f3b9d8ede08e2202d3cd63c42f56c7d2503dc8c6fb9dc5f050b5c17bac<br>
&ndash;control-plane</p>
<p>Then you can join any number of worker nodes by running the following on each as root:</p>
<p>kubeadm join master.k8s.io:16443 &ndash;token ynaob5.49rz8ofxavp6hzes<br>
&ndash;discovery-token-ca-cert-hash sha256:6e7859f3b9d8ede08e2202d3cd63c42f56c7d2503dc8c6fb9dc5f050b5c17bac</p>
<pre><code>
- 6.3 加载环境变量

</code></pre><p>echo &ldquo;export KUBECONFIG=/etc/kubernetes/admin.conf&rdquo; &raquo; ~/.zshrc
source ~/.zshrc</p>
<pre><code>
  本文所有操作都在root用户下执行，若为非root用户，则执行如下操作：

</code></pre><p>mkdir -p $HOME/.kube
cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
chown $(id -u):$(id -g) $HOME/.kube/config</p>
<pre><code>
- 6.4 安装flannel网络

</code></pre><p>kubectl apply -f <a href="https://raw.githubusercontent.com/coreos/flannel/2140ac876ef134e0ed5af15c65e414cf26827915/Documentation/kube-flannel.yml">https://raw.githubusercontent.com/coreos/flannel/2140ac876ef134e0ed5af15c65e414cf26827915/Documentation/kube-flannel.yml</a></p>
<p>podsecuritypolicy.policy/psp.flannel.unprivileged created
clusterrole.rbac.authorization.k8s.io/flannel created
clusterrolebinding.rbac.authorization.k8s.io/flannel created
serviceaccount/flannel created
configmap/kube-flannel-cfg created
daemonset.apps/kube-flannel-ds-amd64 created
daemonset.apps/kube-flannel-ds-arm64 created
daemonset.apps/kube-flannel-ds-arm created
daemonset.apps/kube-flannel-ds-ppc64le created
daemonset.apps/kube-flannel-ds-s390x created</p>
<pre><code>
&lt;center&gt;
&lt;img src=&quot;//zhangzw001.github.io/images/dockerniu.jpeg&quot; width = &quot;100&quot; height = &quot;100&quot; style=&quot;border: 0&quot;/&gt;
&lt;/center&gt;

### 七、control plane节点加入集群

- 7.1 证书分发

  &gt; 在master01.k8s.io上运行脚本cert-main-master.sh，将证书分发至master02.k8s.io

</code></pre><p>tee /root/cert-main-master.sh  &laquo;- &lsquo;EOF&rsquo;
USER=root # customizable
CONTROL_PLANE_IPS=&ldquo;192.168.53.107 192.168.53.108&rdquo;
CONTROL_PLANE_pkidir=&quot;/etc/kubernetes/pki&quot;</p>
<p>for host in ${CONTROL_PLANE_IPS}; do
ssh root@${host} &ldquo;mkdir -p ${CONTROL_PLANE_pkidir}/etcd&rdquo;
scp /etc/kubernetes/pki/ca.crt &ldquo;${USER}&quot;@$host:${CONTROL_PLANE_pkidir}/
scp /etc/kubernetes/pki/ca.key &ldquo;${USER}&quot;@$host:${CONTROL_PLANE_pkidir}/
scp /etc/kubernetes/pki/sa.key &ldquo;${USER}&quot;@$host:${CONTROL_PLANE_pkidir}/
scp /etc/kubernetes/pki/sa.pub &ldquo;${USER}&quot;@$host:${CONTROL_PLANE_pkidir}/
scp /etc/kubernetes/pki/front-proxy-ca.crt &ldquo;${USER}&quot;@$host:${CONTROL_PLANE_pkidir}/
scp /etc/kubernetes/pki/front-proxy-ca.key &ldquo;${USER}&quot;@$host:${CONTROL_PLANE_pkidir}/
scp /etc/kubernetes/pki/etcd/ca.crt &ldquo;${USER}&quot;@$host:${CONTROL_PLANE_pkidir}/etcd/ca.crt
# Quote this line if you are using external etcd
scp /etc/kubernetes/pki/etcd/ca.key &ldquo;${USER}&quot;@$host:${CONTROL_PLANE_pkidir}/etcd/ca.key
done
EOF</p>
<p>sh /root/cert-main-master.sh</p>
<pre><code>
- 7.2 master02.k8s.io,master03.k8s.io加入集群

</code></pre><p>kubeadm join master.k8s.io:16443 &ndash;token ynaob5.49rz8ofxavp6hzes<br>
&ndash;discovery-token-ca-cert-hash sha256:6e7859f3b9d8ede08e2202d3cd63c42f56c7d2503dc8c6fb9dc5f050b5c17bac<br>
&ndash;control-plane</p>
<pre><code>
- 6.3 master02.k8s.io,master03.k8s.io加载环境变量

</code></pre><p>echo &ldquo;export KUBECONFIG=/etc/kubernetes/admin.conf&rdquo; &raquo; ~/.zshrc
source ~/.zshrc</p>
<pre><code>
  本文所有操作都在root用户下执行，若为非root用户，则执行如下操作：

</code></pre><p>mkdir -p $HOME/.kube
cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
chown $(id -u):$(id -g) $HOME/.kube/config</p>
<pre><code>

- 7.4 集群节点查看
</code></pre><h1 id="kubectl-get-nodes">kubectl get nodes<a href="#kubectl-get-nodes" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h1>
<p>NAME              STATUS   ROLES    AGE   VERSION
master01.k8s.io   Ready    master   6m    v1.16.4
master02.k8s.io   Ready    master   99s   v1.16.4
master03.k8s.io   Ready    master   46s   v1.16.4</p>
<h1 id="kubectl-get-pod--n-kube-system">kubectl get pod -n kube-system<a href="#kubectl-get-pod--n-kube-system" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h1>
<p>NAME                                      READY   STATUS    RESTARTS   AGE
coredns-5644d7b6d9-fz77l                  1/1     Running   0          4h
coredns-5644d7b6d9-qvh6b                  1/1     Running   0          4h
etcd-master01.k8s.io                      1/1     Running   1          4h15m
etcd-master02.k8s.io                      1/1     Running   0          4h12m
etcd-master03.k8s.io                      1/1     Running   0          4h11m
kube-apiserver-master01.k8s.io            1/1     Running   1          4h15m
kube-apiserver-master02.k8s.io            1/1     Running   0          4h12m
kube-apiserver-master03.k8s.io            1/1     Running   0          4h10m
kube-controller-manager-master01.k8s.io   1/1     Running   2          4h15m
kube-controller-manager-master02.k8s.io   1/1     Running   1          4h12m
kube-controller-manager-master03.k8s.io   1/1     Running   0          4h10m
kube-flannel-ds-amd64-84b6w               1/1     Running   1          4h15m
kube-flannel-ds-amd64-df99l               1/1     Running   0          4h11m
kube-flannel-ds-amd64-jzt62               1/1     Running   1          4h12m
kube-flannel-ds-amd64-lwd8m               1/1     Running   0          12m
kube-proxy-fgcmg                          1/1     Running   0          4h11m
kube-proxy-mss74                          1/1     Running   0          12m
kube-proxy-r9rz2                          1/1     Running   1          4h16m
kube-proxy-s47gj                          1/1     Running   0          4h12m
kube-scheduler-master01.k8s.io            1/1     Running   2          4h15m
kube-scheduler-master02.k8s.io            1/1     Running   1          4h12m
kube-scheduler-master03.k8s.io            1/1     Running   0          4h10m</p>
<h1 id="kubectl-get-cs">kubectl get cs<a href="#kubectl-get-cs" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h1>
<p>NAME                 AGE
scheduler            <unknown>
controller-manager   <unknown>
etcd-0               <unknown></p>
<pre><code>
  &gt; 执行`kubectl get cs`显示`&lt;unknown&gt;`是一个`1.16`版本已知的`bug`，后续官方应该会解决处理，有大佬分析了源码并且提交了pr，可[点此参考](https://segmentfault.com/a/1190000020912684)


- 7.5 测试集群
</code></pre><h1 id="1-查看leader">1 查看leader<a href="#1-查看leader" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h1>
<h1 id="kubectl-get-endpoints-kube-controller-manager--n-kube-system--o-yaml-grep-holderidentity">kubectl get endpoints kube-controller-manager -n kube-system -o yaml |grep holderIdentity<a href="#kubectl-get-endpoints-kube-controller-manager--n-kube-system--o-yaml-grep-holderidentity" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h1>
<p>control-plane.alpha.kubernetes.io/leader: &lsquo;{&ldquo;holderIdentity&rdquo;:&ldquo;master01.k8s.io_4b4f63f3-551e-4514-8aa9-a8fdbb13f1b4&rdquo;,&ldquo;leaseDurationSeconds&rdquo;:15,&ldquo;acquireTime&rdquo;:&ldquo;2020-03-24T02:40:32Z&rdquo;,&ldquo;renewTime&rdquo;:&ldquo;2020-03-24T02:45:47Z&rdquo;,&ldquo;leaderTransitions&rdquo;:1}&rsquo;</p>
<h1 id="2-在master01k8sio-上执行-init-0-关机-模拟宕机">2 在master01.k8s.io 上执行 init 0 关机 模拟宕机<a href="#2-在master01k8sio-上执行-init-0-关机-模拟宕机" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h1>
<h1 id="3-controller-manager和scheduler也发生了迁移">3 controller-manager和scheduler也发生了迁移<a href="#3-controller-manager和scheduler也发生了迁移" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h1>
<h1 id="kubectl-get-endpoints-kube-controller-manager--n-kube-system--o-yaml-grep-holderidentity-1">kubectl get endpoints kube-controller-manager -n kube-system -o yaml |grep holderIdentity<a href="#kubectl-get-endpoints-kube-controller-manager--n-kube-system--o-yaml-grep-holderidentity-1" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h1>
<p>control-plane.alpha.kubernetes.io/leader: &lsquo;{&ldquo;holderIdentity&rdquo;:&ldquo;master02.k8s.io_457a8d6d-d0e4-4a8e-afbe-0c37f0dadf8d&rdquo;,&ldquo;leaseDurationSeconds&rdquo;:15,&ldquo;acquireTime&rdquo;:&ldquo;2020-03-24T02:46:03Z&rdquo;,&ldquo;renewTime&rdquo;:&ldquo;2020-03-24T02:50:50Z&rdquo;,&ldquo;leaderTransitions&rdquo;:2}&rsquo;</p>
<h1 id="4-集群此时还是能正常操作">4 集群此时还是能正常操作<a href="#4-集群此时还是能正常操作" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h1>
<h1 id="kubectl-get-nodes-1">kubectl get nodes<a href="#kubectl-get-nodes-1" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h1>
<p>NAME              STATUS     ROLES    AGE   VERSION
master01.k8s.io   NotReady   master   17m   v1.16.4
master02.k8s.io   Ready      master   12m   v1.16.4
master03.k8s.io   Ready      master   11m   v1.16.4</p>
<pre><code>
  ![](//zhangzw001.github.io/images/42/02.png)

  ![](//zhangzw001.github.io/images/42/03.png)


- 7.6 导入集群到rancher
</code></pre><h1 id="这里请自行在rancher界面生成我这里是rancherv235">这里请自行在rancher界面生成(我这里是rancherv2.3.5)<a href="#这里请自行在rancher界面生成我这里是rancherv235" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h1>
<p>curl &ndash;insecure -sfL <a href="https://rancher-dev.xxx.com/v3/import/68nzw8nlch92gshktcx2v5d8xvlvlk57nfgffz9jr7hxwfkwcbbtpz.yaml">https://rancher-dev.xxx.com/v3/import/68nzw8nlch92gshktcx2v5d8xvlvlk57nfgffz9jr7hxwfkwcbbtpz.yaml</a> | kubectl apply -f -</p>
<pre><code>
  ![](//zhangzw001.github.io/images/42/04.png)

</code></pre>
			</div>
   

			<hr class="post-end">
			<footer class="post-info">
				<p>
					<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line></svg><span class="tag"><a href="https://www.ngirl.xyz/tags/k8s">k8s</a></span>
				</p>
				<p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline><line x1="16" y1="13" x2="8" y2="13"></line><line x1="16" y1="17" x2="8" y2="17"></line><polyline points="10 9 9 9 8 9"></polyline></svg>1443 Words</p>
				<p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg>2020-03-24 19:10 &#43;0800</p>
			</footer>
		</article>
		<aside id="toc" class="show-toc">
			<div class="toc-title">Table of Contents</div>
			<nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#一-安装准备">一、 安装准备</a></li>
        <li><a href="#二-docker版本安装">二、 docker版本安装</a></li>
        <li><a href="#三-keepalived安装">三、 keepalived安装</a></li>
        <li><a href="#四-haproxy安装">四、 haproxy安装</a></li>
      </ul>
    </li>
  </ul>
</nav>
		</aside>
		<div class="post-nav thin">
			<a class="next-post" href="https://www.ngirl.xyz/posts/43-k8s%E7%9A%84yaml%E9%85%8D%E7%BD%AE%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A-%E6%A8%A1%E6%9D%BF/">
				<span class="post-nav-label"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-left"><line x1="19" y1="12" x2="5" y2="12"></line><polyline points="12 19 5 12 12 5"></polyline></svg>&nbsp;Newer</span><br><span>k8s的yaml配置名词解释(模板)</span>
			</a>
			<a class="prev-post" href="https://www.ngirl.xyz/posts/41-%E8%AE%B0%E4%B8%80%E6%AC%A1es%E9%9B%86%E7%BE%A4%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%E7%9A%84%E9%97%AE%E9%A2%98/">
				<span class="post-nav-label">Older&nbsp;<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-right"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><br><span>记一次es集群内存溢出的问题</span>
			</a>
		</div>
		<div id="comments" class="thin">
						<script src="https://utteranc.es/client.js"
							repo="zhangzw001/blog-hugo"
							issue-term="pathname"
							theme="github-light"
							crossorigin="anonymous"
							async>
			</script>

		</div>
	</main>

	<footer id="site-footer" class="section-inner thin animated fadeIn faster">
		<p>&copy; 2019 - 2021 <a href="https://www.ngirl.xyz">zhangzw</a> &#183; <a href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank" rel="noopener">CC BY-NC 4.0</a></p>
		<p>
			Made with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> &#183; Theme <a href="https://github.com/Track3/hermit" target="_blank" rel="noopener">Hermit</a> &#183; <a href="https://www.ngirl.xyz/post/index.xml" target="_blank" title="rss"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-rss"><path d="M4 11a9 9 0 0 1 9 9"></path><path d="M4 4a16 16 0 0 1 16 16"></path><circle cx="5" cy="19" r="1"></circle></svg></a>
		</p>
	</footer>


	<script src="https://www.ngirl.xyz/js/main.min.784417f5847151f848c339cf0acb13a06cbb648b1483435a28ed4556c4ead69b.js"></script>
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-180942795-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


</body>

</html>
